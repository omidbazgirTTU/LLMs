{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM1JuNY/bEBihH3Ru76mhvU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/omidbazgirTTU/LLMs/blob/main/PPO_implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Proximal Policy Implementation (PPO)\n",
        "## Author Omid Bazgir\n",
        "## Thanks for the great tutorial by Ehsan Kamalinejad (EK)\n",
        "### Linke to the tutorial on YouTube https://www.youtube.com/watch?v=3uvnoVjM8nY&list=PLb9xatikqn0fwsS-Le1mkyQ2uZzK8DeP1&index=3\n",
        "\n",
        "### Basic implementation of PPO (this example is for cart pole program) which is a reinforcement learning (RL) algorithm with many applications including game design, development, large language models (LLMs). PPO is being used in LLMs as as finetuning technique through reinforcement learning with human feedback (RLHF).\n",
        "\n",
        "### more details on the cart pole problem including the how to define the reward values, action space and so on is provided in the Gymnasium documentation https://www.gymlibrary.dev/environments/classic_control/cart_pole/\n",
        "\n",
        "References introduced by EK:\n",
        "- [EK's Video Lecture](https://www.youtube.com/watch?v=3uvnoVjM8nY) This is the lecture where we did a deep dive into the theory of PPO.\n",
        "- [OpenAI PPO Repo](https://github.com/openai/baselines/blob/master/baselines/ppo2/runner.py) This is helpful as a reference for further implementations.\n",
        "- [PPO Paper](https://arxiv.org/abs/1707.06347) This is the original paper that introduced PPO.\n",
        "- [Sergey Levine UC Berkley CS285](http://rail.eecs.berkeley.edu/deeprlcourse/) This is a complete course in RL.\n",
        "- [Pieter Abbeel mini-course](https://www.youtube.com/watch?v=2GwBez0D20A&list=PLwRJQ4m4UJjNymuBM9RdmB3Z9N5-0IlY0) This is a mini-course focusing on TRPO, PPO, DDPG and model free RL.\n",
        "- [OpenAI Documentation on RL](https://spinningup.openai.com/en/latest/index.html) THis is OpenAI documentation on RL and parts of our code was borrowed from here.\n",
        "- [labml.ai](https://nn.labml.ai/) This repo contains popular papers with their annotated PyTorch implementations.\n",
        "- [cleanrl](https://github.com/vwxyzjn/cleanrl) This repo has clean implementations of RL algorithms and parts of our code was borrowed from here.\n",
        "\n"
      ],
      "metadata": {
        "id": "i-CL8MeIeT3h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# installing dependencies\n",
        "!pip install torch --extra-index-url https://download.pytorch.org/whl/cu116\n",
        "!pip install moviepy omegaconf matplotlib\n",
        "!pip install gym==0.26.2\n",
        "!pip install git+https://github.com/carlosluis/stable-baselines3@fix_tests\n",
        "!pip install gym[classic_control] gym[atari] gym[accept-rom-license] gym[other]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5RDbhrg5d9U_",
        "outputId": "fa243e3f-47b4-4900-cbdb-01f7fecb3645"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu116\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.10/dist-packages (1.0.3)\n",
            "Collecting omegaconf\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.66.1)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.31.0)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.1.10)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from moviepy) (1.23.5)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.31.6)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.4.9)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from omegaconf)\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.10/dist-packages (from omegaconf) (6.0.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.46.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from imageio-ffmpeg>=0.2.0->moviepy) (67.7.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2023.11.17)\n",
            "Building wheels for collected packages: antlr4-python3-runtime\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=0ed14226324aa969d5478c439b9e8505803ed644ac021e6e4c9efd9430867018\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
            "Successfully built antlr4-python3-runtime\n",
            "Installing collected packages: antlr4-python3-runtime, omegaconf\n",
            "Successfully installed antlr4-python3-runtime-4.9.3 omegaconf-2.3.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pydevd_plugins"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gym==0.26.2\n",
            "  Downloading gym-0.26.2.tar.gz (721 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/721.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.9/721.7 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m491.5/721.7 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m721.7/721.7 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from gym==0.26.2) (1.23.5)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym==0.26.2) (2.2.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym==0.26.2) (0.0.8)\n",
            "Building wheels for collected packages: gym\n",
            "  Building wheel for gym (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gym: filename=gym-0.26.2-py3-none-any.whl size=827621 sha256=9b7ccf2ba04bc2a825a5e509ed9bc1bf2655322d039dea4acb210e45b9d251c4\n",
            "  Stored in directory: /root/.cache/pip/wheels/b9/22/6d/3e7b32d98451b4cd9d12417052affbeeeea012955d437da1da\n",
            "Successfully built gym\n",
            "Installing collected packages: gym\n",
            "  Attempting uninstall: gym\n",
            "    Found existing installation: gym 0.25.2\n",
            "    Uninstalling gym-0.25.2:\n",
            "      Successfully uninstalled gym-0.25.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dopamine-rl 4.0.6 requires gym<=0.25.2, but you have gym 0.26.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gym-0.26.2\n",
            "Collecting git+https://github.com/carlosluis/stable-baselines3@fix_tests\n",
            "  Cloning https://github.com/carlosluis/stable-baselines3 (to revision fix_tests) to /tmp/pip-req-build-3mt4z1ku\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/carlosluis/stable-baselines3 /tmp/pip-req-build-3mt4z1ku\n",
            "  Running command git checkout -b fix_tests --track origin/fix_tests\n",
            "  Switched to a new branch 'fix_tests'\n",
            "  Branch 'fix_tests' set up to track remote branch 'fix_tests' from 'origin'.\n",
            "  Resolved https://github.com/carlosluis/stable-baselines3 to commit 6617e6e73cb3a70f3e88cea780ea12bed95c099e\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: gym==0.26.2 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3==2.0.0a0) (0.26.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from stable-baselines3==2.0.0a0) (1.23.5)\n",
            "Requirement already satisfied: torch>=1.11 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3==2.0.0a0) (2.1.0+cu121)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from stable-baselines3==2.0.0a0) (2.2.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from stable-baselines3==2.0.0a0) (1.5.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from stable-baselines3==2.0.0a0) (3.7.1)\n",
            "Collecting importlib-metadata~=4.13 (from stable-baselines3==2.0.0a0)\n",
            "  Downloading importlib_metadata-4.13.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym==0.26.2->stable-baselines3==2.0.0a0) (0.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata~=4.13->stable-baselines3==2.0.0a0) (3.17.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->stable-baselines3==2.0.0a0) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->stable-baselines3==2.0.0a0) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->stable-baselines3==2.0.0a0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->stable-baselines3==2.0.0a0) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->stable-baselines3==2.0.0a0) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->stable-baselines3==2.0.0a0) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->stable-baselines3==2.0.0a0) (2.1.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3==2.0.0a0) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3==2.0.0a0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3==2.0.0a0) (4.46.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3==2.0.0a0) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3==2.0.0a0) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3==2.0.0a0) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3==2.0.0a0) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3==2.0.0a0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->stable-baselines3==2.0.0a0) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->stable-baselines3==2.0.0a0) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11->stable-baselines3==2.0.0a0) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11->stable-baselines3==2.0.0a0) (1.3.0)\n",
            "Building wheels for collected packages: stable-baselines3\n",
            "  Building wheel for stable-baselines3 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for stable-baselines3: filename=stable_baselines3-2.0.0a0-py3-none-any.whl size=174557 sha256=e80318046f4a5814692a4e89cfa558e2db1b88f0217954f145eaf477cabb2654\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-nfn1kscj/wheels/cc/40/56/e6db2f8ff9427b0849f4c6ddbe003a53a5f61f31aae2f9ccb7\n",
            "Successfully built stable-baselines3\n",
            "Installing collected packages: importlib-metadata, stable-baselines3\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib-metadata 7.0.0\n",
            "    Uninstalling importlib-metadata-7.0.0:\n",
            "      Successfully uninstalled importlib-metadata-7.0.0\n",
            "Successfully installed importlib-metadata-4.13.0 stable-baselines3-2.0.0a0\n",
            "Requirement already satisfied: gym[classic_control] in /usr/local/lib/python3.10/dist-packages (0.26.2)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from gym[classic_control]) (1.23.5)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym[classic_control]) (2.2.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym[classic_control]) (0.0.8)\n",
            "Collecting pygame==2.1.0 (from gym[classic_control])\n",
            "  Downloading pygame-2.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ale-py~=0.8.0 (from gym[classic_control])\n",
            "  Downloading ale_py-0.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m66.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting autorom[accept-rom-license]~=0.4.2 (from gym[classic_control])\n",
            "  Downloading AutoROM-0.4.2-py3-none-any.whl (16 kB)\n",
            "Collecting lz4>=3.1.0 (from gym[classic_control])\n",
            "  Downloading lz4-4.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m67.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opencv-python>=3.0 in /usr/local/lib/python3.10/dist-packages (from gym[classic_control]) (4.8.0.76)\n",
            "Requirement already satisfied: matplotlib>=3.0 in /usr/local/lib/python3.10/dist-packages (from gym[classic_control]) (3.7.1)\n",
            "Requirement already satisfied: moviepy>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from gym[classic_control]) (1.0.3)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from ale-py~=0.8.0->gym[classic_control]) (6.1.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from ale-py~=0.8.0->gym[classic_control]) (4.5.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[classic_control]) (8.1.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[classic_control]) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[classic_control]) (4.66.1)\n",
            "Collecting AutoROM.accept-rom-license (from autorom[accept-rom-license]~=0.4.2->gym[classic_control])\n",
            "  Downloading AutoROM.accept-rom-license-0.6.1.tar.gz (434 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.7/434.7 kB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->gym[classic_control]) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->gym[classic_control]) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->gym[classic_control]) (4.46.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->gym[classic_control]) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->gym[classic_control]) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->gym[classic_control]) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->gym[classic_control]) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->gym[classic_control]) (2.8.2)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from moviepy>=1.0.0->gym[classic_control]) (4.4.2)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.10/dist-packages (from moviepy>=1.0.0->gym[classic_control]) (0.1.10)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.10/dist-packages (from moviepy>=1.0.0->gym[classic_control]) (2.31.6)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from moviepy>=1.0.0->gym[classic_control]) (0.4.9)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from imageio-ffmpeg>=0.2.0->moviepy>=1.0.0->gym[classic_control]) (67.7.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.0->gym[classic_control]) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[classic_control]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[classic_control]) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[classic_control]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[classic_control]) (2023.11.17)\n",
            "Building wheels for collected packages: AutoROM.accept-rom-license\n",
            "  Building wheel for AutoROM.accept-rom-license (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for AutoROM.accept-rom-license: filename=AutoROM.accept_rom_license-0.6.1-py3-none-any.whl size=446660 sha256=f7907442c217867adb92f616936a118b197bd0cdbbd8b8689d1554ae2e95e137\n",
            "  Stored in directory: /root/.cache/pip/wheels/6b/1b/ef/a43ff1a2f1736d5711faa1ba4c1f61be1131b8899e6a057811\n",
            "Successfully built AutoROM.accept-rom-license\n",
            "Installing collected packages: pygame, lz4, ale-py, AutoROM.accept-rom-license, autorom\n",
            "  Attempting uninstall: pygame\n",
            "    Found existing installation: pygame 2.5.2\n",
            "    Uninstalling pygame-2.5.2:\n",
            "      Successfully uninstalled pygame-2.5.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dopamine-rl 4.0.6 requires gym<=0.25.2, but you have gym 0.26.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed AutoROM.accept-rom-license-0.6.1 ale-py-0.8.1 autorom-0.4.2 lz4-4.3.2 pygame-2.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pylab as plt\n",
        "plt.style.use('dark_background')\n",
        "from tqdm.notebook import tqdm\n",
        "from omegaconf import DictConfig\n",
        "\n",
        "import gym\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.distributions.categorical import Categorical\n",
        "\n",
        "from IPython.display import Video"
      ],
      "metadata": {
        "id": "vMQjpnItf6A0"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set up\n",
        "seed = 7\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.backends.cudnn.deterministic = True\n"
      ],
      "metadata": {
        "id": "-kZgZruCgOBP"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "93RQAMK5gpXZ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "configs = {\n",
        "    # experiment arguments\n",
        "    \"exp_name\": \"cartpole\",\n",
        "    \"gym_id\": \"CartPole-v1\", # the id of from OpenAI gym\n",
        "    # training arguments\n",
        "    \"learning_rate\": 1e-3, # the learning rate of the optimizer\n",
        "    \"total_timesteps\": 1000000, # total timesteps of the training\n",
        "    \"max_grad_norm\": 0.5, # the maximum norm allowed for the gradient\n",
        "    # PPO parameters\n",
        "    \"num_trajcts\": 32, # N\n",
        "    \"max_trajects_length\": 64, # T\n",
        "    \"gamma\": 0.99, # gamma\n",
        "    \"gae_lambda\":0.95, # lambda for the generalized advantage estimation\n",
        "    \"num_minibatches\": 2, # number of mibibatches used in each gradient\n",
        "    \"update_epochs\": 2, # number of full rollout storage creations\n",
        "    \"clip_epsilon\": 0.2, # the surrogate clipping coefficient\n",
        "    \"ent_coef\": 0.01, # entroy coefficient controlling the exploration factor C2\n",
        "    \"vf_coef\": 0.5, # value function controlling value estimation importance C1\n",
        "    # visualization and print parameters\n",
        "    \"num_returns_to_average\": 3, # how many episodes to use for printing average return\n",
        "    \"num_episodes_to_average\": 23, # how many episodes to use for smoothing of the return diagram\n",
        "    }\n",
        "\n",
        "# batch_size is the size of the flatten sequences when trajcts are flatten\n",
        "configs['batch_size'] = int(configs['num_trajcts'] * configs['max_trajects_length'])\n",
        "# number of samples used in each gradient\n",
        "configs['minibatch_size'] = int(configs['batch_size'] // configs['num_minibatches'])\n",
        "\n",
        "configs = DictConfig(configs)\n",
        "\n",
        "run_name = f\"{configs.gym_id}__{configs.exp_name}__{seed}__{int(time.time())}\""
      ],
      "metadata": {
        "id": "XEC7N3Dmgy_m"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ENV\n",
        "`envs` us set of parallel environments each holding a random initiali `state` and accepts an `action` to change and return its new state."
      ],
      "metadata": {
        "id": "WWyv6MMjh-PH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creating an env with random state\n",
        "def make_env_func(gym_id, seed, idx, run_name, capture_video = False):\n",
        "  def env_fun():\n",
        "    env = gym.make(gym_id, render_mode = \"rgb_gray\")\n",
        "    env = gym.wrappers.RecordEpisodeStatistics(env)\n",
        "    if capture_video:\n",
        "      # initiate the video capture if not already initiated\n",
        "      if idx ==0:\n",
        "        #wrapper to create the video of the performance\n",
        "        env = gym.wrappers.RecordVideo(env, f\"videos/{run_name}\")\n",
        "    env.action_space.seed(seed)\n",
        "    env.observation_space.seed(seed)\n",
        "\n",
        "    return env\n",
        "  return env_fun"
      ],
      "metadata": {
        "id": "_M6xogrBiU88"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create N (here is 32) parallel envs\n",
        "envs = []\n",
        "for i in range(configs.num_trajcts):\n",
        "  envs.append(make_env_func(configs.gym_id, seed+i, i, run_name))\n",
        "envs = gym.vector.SyncVectorEnv(envs)\n",
        "envs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsTSdYPqjqwn",
        "outputId": "e582e8dd-3eda-4ed4-bf3e-11938276e4f4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py:623: UserWarning: \u001b[33mWARN: The environment is being initialised with mode (rgb_gray) that is not in the possible render_modes (['human', 'rgb_array']).\u001b[0m\n",
            "  logger.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SyncVectorEnv(32)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model\n",
        "A simple MLP (or fully connected layers FC) model that gets a state and has two methods:\n",
        "* `agent.value_func(state)` gets a state and returns the estimated expected total feature rewards from that state $V_{\\theta}(s)$.\n",
        "\n",
        "* `agent.policy(state)` gets a state and returns next `action`, `log_prob` of actions, the `entropy` and `value`."
      ],
      "metadata": {
        "id": "VhAEm15CkF6e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FCBlock(nn.Module):\n",
        "  \"\"\" a generic fully connected residual block with good set up\"\"\"\n",
        "  def __init__(self, embed_dim, dropout = 0.2):\n",
        "    super().__init__()\n",
        "    self.block = nn.Sequential(\n",
        "        nn.LayerNorm(embed_dim),\n",
        "        nn.GELU(),\n",
        "        nn.Linear(embed_dim, 4*embed_dim),\n",
        "        nn.GELU(),\n",
        "        nn.Linear(4*embed_dim, embed_dim),\n",
        "        nn.Dropout(dropout)\n",
        "    )\n",
        "\n",
        "    def forward(self, x):\n",
        "      return x + self.block(x)\n",
        "\n",
        "  class Agent(nn.Module):\n",
        "    \"\"\" an agent that creates actions and estimates values\"\"\"\n",
        "    def __init__(self, env_observation_dim, action_space_dim, embed_dim = 64, num_blocks=2):\n",
        "      super().__init__()\n",
        "      # getting the observation and embed that into another space `embed_dim`\n",
        "      self.embedding_layer = nn.Linear(env_observation_dim, embed_dim)\n",
        "      # layers that are shared between policy head and value head\n",
        "      # it not necessarily needed to have a shared layer, but here since that value and policy tasks are quite similar\n",
        "      # we can use several shared layer to do multi-task learning\n",
        "      self.shared_layers = nn.Sequential(*[FCBlock(embed_dim=embed_dim) for _ in range(num_blocks)])\n",
        "      self.value_head = nn.Linear(embed_dim, 1)\n",
        "      self.policy_head = nn.Linear(embed_dim, action_space_dim)\n",
        "      # orthogonal initialization with a hi entropy for exploration at the start\n",
        "      torch.nn.init.orthogonal_(self.policy_head.weight, 0.01)\n",
        "\n",
        "    def value_func(self,state):\n",
        "      hidden = self.shared_layers(self.embedding_layer(state))\n",
        "      value = self.value_head(hidden)\n",
        "      return value\n",
        "\n",
        "    def policy(self, state, action=None):\n",
        "      # plicy is supposed to create actions but here it takes actions as the input\n",
        "      # this is for phase 2 of PPO where we want to analze the actions\n",
        "      hidden = self.shared_layers(self.embedding_layer(state))\n",
        "      logits = self.policy_head(hidden)\n",
        "      # Pytoch categorical class for sampling and probability calcucation\n",
        "      probs = Categorical(logits=logits)\n",
        "      if action is None:\n",
        "        action = probs.sample()\n",
        "      return action, probs.log_prob(action), probs.entropy(), self.value_head(hidden)"
      ],
      "metadata": {
        "id": "WpUuRBcTk38V"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generalized Advantage Estimation (GAE)\n",
        "\n",
        "### $Advantage (s, a)$ calculates how better or worse the return of taking the action $a$ at the state $s$ is compared to expected return for all other actions in that state.\n",
        "\n",
        "### we can approximate that with the below reverse formulas\n",
        "\n",
        "$δ_{t} = r_{t} + γV(s_{t+1}) - V(s_{t})$\n",
        "\n",
        "$\\hat{A_{t}} = δ_{t} + γλ\\hat{A}_{t+1}$\n"
      ],
      "metadata": {
        "id": "Xk-6HbWcrwJU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gae(\n",
        "    cur_observations,   # the current state when advantages will be calculated\n",
        "    rewards,            # rewards collected from trajectories of shape [num_trajcts, max_trajcts_length]\n",
        "    dones,              # binary marker of end of trajectories of shape [num_trajcts, max_trajcts_length]\n",
        "    values,             # value estimates collected over trajectories of shape [num_trajcts, max_trajcts_length]\n",
        "):\n",
        "\n",
        "  advantages = torch.zeros((configs.num_trajcts, configs.max_trajects_length))\n",
        "  last_advantage = 0\n",
        "\n",
        "  # the value after the last step\n",
        "  with torch.no_grad():\n",
        "    last_value = agent.value_func(cur_observations).reshape(1,-1)\n",
        "\n",
        "  # reverse recursive to calculate advantages based on the delta formula\n",
        "  for t in reversed(range(configs.max_trajects_length)):\n",
        "    # mask if episode completed after step t\n",
        "    mask = 1.0 - dones[:,t] # --> if we are looking for those trajectories that were ended quicker we don't need to any further calculation so we use the variable mask\n",
        "    last_value = last_value * mask\n",
        "    last_advantage = last_advantage * mask\n",
        "    delta = rewards[:,t] + configs.gamma * last_value - values[:,t]\n",
        "    last_advantage = delta + configs.gamma * configs.gae_lambda * last_advantage\n",
        "    advantages[:,t] = last_advantage\n",
        "    last_value = values[:,t]\n",
        "\n",
        "  advantages = advantages.to(device)\n",
        "  returns = advantages + values\n",
        "\n",
        "  return advantages, returns"
      ],
      "metadata": {
        "id": "-IPXHfFmz8rT"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating Rollout stage\n",
        "\n",
        "### Phase 1: rollout creation\n",
        "\n",
        "1. Generate $N$ trajectories of length $T$ by $\\pi_{θ_{old}}$\n",
        "2. calculate $logits_{old}$ for the actions\n",
        "3. calculate $V_{theta}$ along the trajectories\n",
        "4. calculate advantage estimates $\\hat{A}_{t}$\n",
        "5. create a storage and add all items to it"
      ],
      "metadata": {
        "id": "CvRwdFGi2stp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_rollout(\n",
        "    envs,               # parallel envs creating trajectories\n",
        "    cur_observations,   # starting observation of shape [num_trajcts, observation_dim]\n",
        "    cur_done,           # current termination status of shape [num_trajcts,]\n",
        "    all_returns         # a list to track returns\n",
        ")\n",
        "  \"\"\"\n",
        "  rollout phase: create parallel trajectories and store them in the rolout storage\n",
        "  \"\"\"\n",
        "\n",
        "  # cache empty tensors to store the rollouts"
      ],
      "metadata": {
        "id": "1oQ2TX1g30cW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}